# -*- coding: utf-8 -*-
"""aircraft damage model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w_p1-ZKyd1QBFOMHOS6d6bVDM7Ge9qUN
"""

import warnings
warnings.filterwarnings("ignore")

import os
import random
import tarfile
import urllib.request
import shutil

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import torch

from PIL import Image
from transformers import BlipProcessor, BlipForConditionalGeneration

from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.applications import VGG16
from keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator

SEED = 42
random.seed(SEED)
np.random.seed(SEED)

BATCH_SIZE = 32
EPOCHS = 10
IMG_SIZE = (224, 224)
INPUT_SHAPE = (224, 224, 3)

DATASET_URL = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/ZjXM4RKxlBK9__ZjHBLl5A/aircraft-damage-dataset-v1.tar"
TAR_FILE = "aircraft_damage_dataset_v1.tar"
DATASET_DIR = "aircraft_damage_dataset_v1"

if not os.path.exists(TAR_FILE):
    print("Downloading dataset...")
    urllib.request.urlretrieve(DATASET_URL, TAR_FILE)

if os.path.exists(DATASET_DIR):
    shutil.rmtree(DATASET_DIR)

print("Extracting dataset...")
with tarfile.open(TAR_FILE, "r") as tar:
    tar.extractall()

TRAIN_DIR = os.path.join(DATASET_DIR, "train")
VALID_DIR = os.path.join(DATASET_DIR, "valid")
TEST_DIR  = os.path.join(DATASET_DIR, "test")

datagen = ImageDataGenerator(rescale=1./255)

train_gen = datagen.flow_from_directory(
    TRAIN_DIR,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="binary",
    shuffle=True
)

valid_gen = datagen.flow_from_directory(
    VALID_DIR,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="binary",
    shuffle=False
)

test_gen = datagen.flow_from_directory(
    TEST_DIR,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="binary",
    shuffle=False
)

base_model = VGG16(
    weights="imagenet",
    include_top=False,
    input_shape=INPUT_SHAPE
)

for layer in base_model.layers:
    layer.trainable = False

damage_model = Sequential([
    base_model,
    Flatten(),
    Dense(512, activation="relu"),
    Dropout(0.3),
    Dense(512, activation="relu"),
    Dropout(0.3),
    Dense(1, activation="sigmoid")
])

damage_model.compile(
    optimizer=Adam(learning_rate=0.0001),
    loss="binary_crossentropy",
    metrics=["accuracy"]
)

damage_model.summary()

history = damage_model.fit(
    train_gen,
    epochs=EPOCHS,
    validation_data=valid_gen
)

test_loss, test_acc = damage_model.evaluate(test_gen)
print(f"Test Accuracy: {test_acc:.4f}")

plt.figure(figsize=(6,4))
plt.plot(history.history["accuracy"], label="Train Accuracy")
plt.plot(history.history["val_accuracy"], label="Val Accuracy")
plt.legend()
plt.title("Accuracy Curve")
plt.show()

plt.figure(figsize=(6,4))
plt.plot(history.history["loss"], label="Train Loss")
plt.plot(history.history["val_loss"], label="Val Loss")
plt.legend()
plt.title("Loss Curve")
plt.show()

processor = BlipProcessor.from_pretrained(
    "Salesforce/blip-image-captioning-base"
)
blip_model = BlipForConditionalGeneration.from_pretrained(
    "Salesforce/blip-image-captioning-base"
)

class BlipCaptionSummaryLayer(tf.keras.layers.Layer):
    def __init__(self, processor, model):
        super().__init__()
        self.processor = processor
        self.model = model

    def call(self, image_path, task):
        return tf.py_function(
            self._process,
            [image_path, task],
            tf.string
        )

    def _process(self, image_path, task):
        try:
            image_path = image_path.numpy().decode("utf-8")
            task = task.numpy().decode("utf-8")

            image = Image.open(image_path).convert("RGB")

            prompt = (
                "This is a picture of"
                if task == "caption"
                else "This is a detailed photo showing"
            )

            inputs = self.processor(
                images=image,
                text=prompt,
                return_tensors="pt"
            )

            with torch.no_grad():
                output = self.model.generate(**inputs)

            return self.processor.decode(
                output[0],
                skip_special_tokens=True
            )

        except Exception as e:
            return f"Error: {str(e)}"

def generate_text(image_path, task):
    layer = BlipCaptionSummaryLayer(processor, blip_model)
    return layer(
        tf.constant(image_path),
        tf.constant(task)
    )

sample_image = (
    "aircraft_damage_dataset_v1/test/dent/"
    "149_22_JPG_jpg.rf.4899cbb6f4aad9588fa3811bb886c34d.jpg"
)

# Display image
img = plt.imread(sample_image)
plt.imshow(img)
plt.axis("off")
plt.show()

# Generate Caption
caption = generate_text(sample_image, "caption")
print("Caption:", caption.numpy().decode("utf-8"))

# Generate Summary
summary = generate_text(sample_image, "summary")
print("Summary:", summary.numpy().decode("utf-8"))

from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    confusion_matrix,
    classification_report,
    roc_auc_score,
    roc_curve
)
import seaborn as sns

# Reset generator to avoid data leakage
test_gen.reset()

# Get predicted probabilities
y_prob = damage_model.predict(test_gen)

# Convert probabilities to class labels (0 or 1)
y_pred = (y_prob > 0.5).astype(int).ravel()

# True labels
y_true = test_gen.classes

accuracy  = accuracy_score(y_true, y_pred)
precision = precision_score(y_true, y_pred)
recall    = recall_score(y_true, y_pred)
f1        = f1_score(y_true, y_pred)
roc_auc   = roc_auc_score(y_true, y_prob)

print("Model Evaluation Metrics")
print("------------------------")
print(f"Accuracy  : {accuracy:.4f}")
print(f"Precision : {precision:.4f}")
print(f"Recall    : {recall:.4f}")
print(f"F1-Score  : {f1:.4f}")
print(f"ROC-AUC   : {roc_auc:.4f}")

print("\nClassification Report:")
print(classification_report(
    y_true,
    y_pred,
    target_names=list(test_gen.class_indices.keys())
))

cm = confusion_matrix(y_true, y_pred)

plt.figure(figsize=(5,4))
sns.heatmap(
    cm,
    annot=True,
    fmt="d",
    cmap="Blues",
    xticklabels=test_gen.class_indices.keys(),
    yticklabels=test_gen.class_indices.keys()
)

plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

fpr, tpr, _ = roc_curve(y_true, y_prob)

plt.figure(figsize=(5,4))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.2f}")
plt.plot([0,1], [0,1], linestyle="--")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.show()





































